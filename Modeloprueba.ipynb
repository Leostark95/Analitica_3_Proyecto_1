{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Selección de Variables Numéricas"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.feature_selection import RFE\n",
    "from sklearn.linear_model import LogisticRegression\n",
    "from sklearn.feature_selection import VarianceThreshold\n",
    "from sklearn.feature_selection import SelectKBest, f_regression, mutual_info_regression,  f_classif, mutual_info_classif, chi2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_2015 = \n",
    "df_2016 = "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "EmployeeID, DateSurvey, EnvironmentSatisfaction, JobSatisfaction, WorkLifeBalance\n",
    "\n",
    "EmployeeID, InfoDate, Age, BusinessTravel, Department, DistanceFromHome, Education, \n",
    "    JobRole, MonthlyIncome, NumCompaniesWorked, PercentSalaryHike, TrainingTimesLastYear, \n",
    "    YearsAtCompany, YearsSinceLastPromotion\n",
    "\n",
    "EmployeeID, SurveyDate, JobInvolvement, PerformanceRating\n",
    "\n",
    "EmployeeID, retirementDate, retirementType\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Métodos de Filtrado"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "\n",
    "Umbral de Varianza"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "x_numericos = df.select_dtypes(include = [\"number\"]) # solo variables númericas\n",
    "x_numericos.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "x_numericos.describe()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Función de filtro de caracteristicas\n",
    "def variance_threshold(X,th): # recibe el dataframe y el umbral\n",
    "    var_thres = VarianceThreshold(threshold=th) # crea la función con base en el umbral\n",
    "    var_thres.fit(X) # alimenta los datos con la función creada\n",
    "    new_cols = var_thres.get_support() # devuelve las columnas\n",
    "    return new_cols"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Normalizar los datos\n",
    "df1 = x_numericos.copy(deep = True)  # crear una copia del DataFrame\n",
    "scaler = MinMaxScaler() # asignar el tipo de normalización\n",
    "sv = scaler.fit_transform(df1.iloc[:,:]) # normalizar los datos\n",
    "df1.iloc[:,:] = sv # asignar los nuevos datos\n",
    "df1.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df1.describe() # miremos sus metricas"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Obtener columnas seleccionadas\n",
    "import math as mt\n",
    "\n",
    "# Parametros para definir que era constante:\n",
    "desviacion = 0.21 # eliminar todo cuya desviación estandar sea menor a 0.21, teniendo en cuenta tabla anterior\n",
    "varianza = desviacion**2\n",
    "\n",
    "# Resultados\n",
    "print('Desviación estandar:', mt.sqrt(varianza))\n",
    "print('Varianza:', varianza)\n",
    "x_new = variance_threshold(df1, varianza)\n",
    "df_new_int = df1.iloc[:,x_new] # nuevo dataframe\n",
    "df_new_int.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Selección Univariante"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "x_num = df.select_dtypes(include = [\"number\"]) # filtrar solo variables númericas\n",
    "y = df['Credit Risk']\n",
    "x_num.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Normalización de datos\n",
    "x_num_norm = x_num.copy(deep = True)  # copia\n",
    "scaler = MinMaxScaler() # Se usará minmaxScaler\n",
    "sv = scaler.fit_transform(x_num_norm.iloc[:,:]) # normalizar los datos\n",
    "x_num_norm.iloc[:,:] = sv # asignar los nuevos datos\n",
    "x_num_norm.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Función de filtro de caracteristicas - stadis. scores\n",
    "def select_kbest(X,y,score_f,k): #se establece una funcion que permite sacar varias funciones de evaluacion\n",
    "    sel_kb = SelectKBest(score_func=score_f, k=k)\n",
    "    sel_kb.fit(X,y)\n",
    "    scores = sel_kb.scores_\n",
    "    pvalues = sel_kb.pvalues_\n",
    "    new_cols = sel_kb.get_support()\n",
    "    print(\"Scores:\\n\", scores, \"\\nP-values:\\n\", pvalues)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#F Classif \n",
    "x_new, scores, pvalues = select_kbest(x_num_norm, y,  f_classif, 3) # Obtener columnas seleciconadas - (3 caracteristicas)\n",
    "df_new = x_num.iloc[:,x_new] # Nuevo conjunto de datos\n",
    "df_new.head() #se escogen los valores p mas pequeños, y las variables tiene relacion con la variable objetivo\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def plot(metric, features, name):\n",
    "    features = features\n",
    "    fig, ax = plt.subplots(figsize=(10, 6))  # Ajuste el tamaño de la figura según sea necesario\n",
    "    width = 0.4  # Ancho de las barras\n",
    "    ax.bar(np.arange(len(metric)), metric, width=width)\n",
    "    ax.set_xlabel('Features')\n",
    "    ax.set_ylabel(name)\n",
    "    ax.set_xticks(np.arange(len(metric)))\n",
    "    ax.set_xticklabels(features)\n",
    "    plt.xticks(rotation=45, ha='right')  # Rotar etiquetas para mejor visualización\n",
    "    plt.tight_layout()  # Ajustar el diseño para evitar superposiciones\n",
    "    return plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "plot(scores, x_num.columns, 'F-values')\n",
    "plot(pvalues, x_num.columns, 'P-values')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Métodos Wrapper "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "RFE (Recursive Feature Elimination)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Función recursiva de selección de características\n",
    "def recursive_feature_selection(X,y,model,k): #model=modelo que me va a servir de estimador en este caso de regresión logística\n",
    "  rfe = RFE(model, n_features_to_select=k, step=1)# step=1 cada cuanto el toma la sucesión de tomar una caracteristica\n",
    "  fit = rfe.fit(X, y)\n",
    "  X_new = fit.support_\n",
    "  print(\"Num Features: %s\" % (fit.n_features_))\n",
    "  print(\"Selected Features: %s\" % (fit.support_))\n",
    "  print(\"Feature Ranking: %s\" % (fit.ranking_))\n",
    "\n",
    "  return X_new"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#  Estimador en este caso para regresión logística (problema de clasificación)\n",
    "model = LogisticRegressionCV()\n",
    "\n",
    "# Obtener columnas seleciconadas - (4 caracteristicas)\n",
    "X_new = recursive_feature_selection(x_num_norm, y, model, 4)\n",
    "\n",
    "# Nuevo conjunto de datos\n",
    "df_new = x_num.iloc[:,X_new]\n",
    "df_new.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Métodos Integrados "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Regresión Ridge"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Selector con un modelo de regresión logística\n",
    "sel_ = SelectFromModel(LogisticRegression(penalty='l2', C=1.0))  # Usamos 'l2' para regularización Ridge\n",
    "\n",
    "sel_.fit(x_num_norm, y)\n",
    "\n",
    "# Obtener variables seleccionadas\n",
    "X_new = sel_.get_support()\n",
    "\n",
    "df_new = x_num.iloc[:, X_new]\n",
    "print(df_new.head())"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
